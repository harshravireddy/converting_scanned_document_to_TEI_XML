{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9FchUA-M1Haq"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Read the HOCR file\n",
        "with open(\"OCR-D-HOCR-Final_20240110-142856_2-2.xml\", \"r\", encoding=\"utf-8\") as file:\n",
        "    hocr_content = file.read()\n",
        "\n",
        "# Parse the HOCR content\n",
        "soup = BeautifulSoup(hocr_content, \"html.parser\")\n",
        "\n",
        "# Find the div with class \"ocr_carea\" and title attribute containing \"bbox 271 2112 1554 2169\"\n",
        "div_place_tag = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 271 2112 1554 2169\" in value)\n",
        "\n",
        "place_text = \"\"\n",
        "\n",
        "# Extract text from the found div\n",
        "if div_place_tag:\n",
        "    text = div_place_tag.get_text(strip=True)\n",
        "    # Match both \"Leipzig\" and \"Berlin\" using regular expression\n",
        "    matches = re.findall(r'\\b(?:Leipzig|Berlin)\\b', text)\n",
        "    if matches:\n",
        "        place_text = \" und \".join(matches)  # Join the matches with \" und \" in between\n",
        "\n",
        "# Find the div with class \"ocr_carea\" and title attribute containing \"bbox 271 2112 1554 2169\"\n",
        "div_org_name_tag = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 271 2112 1554 2169\" in value)\n",
        "\n",
        "# Extract text from the third div with the specified format for orgName\n",
        "if div_org_name_tag:\n",
        "    org_name_text = \"\"\n",
        "    text = div_org_name_tag.get_text(strip=True)\n",
        "    match = re.search(r\"\\b[A-Z]\\.[A-Z]\\. [A-Z][a-z]+\\b\", text)\n",
        "    if match:\n",
        "        org_name_text = match.group(0)\n",
        "else:\n",
        "    org_name_text = \"\"\n",
        "\n",
        "div_p1 = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 271 210 1561 347\" in value)\n",
        "\n",
        "# Extract text from the first div\n",
        "if div_p1:\n",
        "    p1 = div_p1.get_text(strip=True)\n",
        "else:\n",
        "    p1 = \"\"\n",
        "\n",
        "div_h1 = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 273 375 1320 448\" in value)\n",
        "\n",
        "# Extract text from the first div\n",
        "if div_h1:\n",
        "    h1 = div_h1.get_text(strip=True)\n",
        "else:\n",
        "    h1 = \"\"\n",
        "\n",
        "div_p2 = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 377 462 1559 601\" in value)\n",
        "\n",
        "# Extract text from the first div\n",
        "if div_p2:\n",
        "    p2 = div_p2.get_text(strip=True)\n",
        "else:\n",
        "    p2 = \"\"\n",
        "\n",
        "div_p3 = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 271 615 1559 841\" in value)\n",
        "\n",
        "# Extract text from the first div\n",
        "if div_p3:\n",
        "    p3 = div_p3.get_text(strip=True)\n",
        "else:\n",
        "    p3 = \"\"\n",
        "\n",
        "div_p4 = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 273 911 946 965\" in value)\n",
        "\n",
        "# Extract text from the first div\n",
        "if div_p4:\n",
        "    p4 = div_p4.get_text(strip=True)\n",
        "else:\n",
        "    p4 = \"\"\n",
        "\n",
        "div_h2 = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 274 995 1404 1069\" in value)\n",
        "\n",
        "# Extract text from the first div\n",
        "if div_h2:\n",
        "    h2 = div_h2.get_text(strip=True)\n",
        "else:\n",
        "    h2 = \"\"\n",
        "\n",
        "div_p5 = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 379 1078 1556 1305\" in value)\n",
        "\n",
        "# Extract text from the first div\n",
        "if div_p5:\n",
        "    p5 = div_p5.get_text(strip=True)\n",
        "else:\n",
        "    p5 = \"\"\n",
        "\n",
        "div_p6 = soup.find(\"div\", class_=\"ocr_carea\", title=lambda value: value and \"bbox 271 1317 1556 1541\" in value)\n",
        "\n",
        "# Extract text from the first div\n",
        "if div_p6:\n",
        "    p6 = div_p6.get_text(strip=True)\n",
        "else:\n",
        "    p6 = \"\"\n",
        "\n",
        "# Create TEI XML document\n",
        "tei_xml = f\"\"\"\n",
        "<TEI>\n",
        "  <teiHeader>\n",
        "    <fileDesc>\n",
        "        <orgName>{org_name_text}</orgName>\n",
        "      <publicationStmt>\n",
        "        <publPlace>{place_text}</publPlace>\n",
        "      </publicationStmt>\n",
        "    </fileDesc>\n",
        "  </teiHeader>\n",
        "  <text>\n",
        "    <body>\n",
        "      <div>\n",
        "        <p>{p1}</p>\n",
        "        <head>{h1}</head>\n",
        "        <p>{p2}</p>\n",
        "        <p>{p3}</p>\n",
        "        <p>{p4}</p>\n",
        "        <head>{h2}</head>\n",
        "        <p>{p5}</p>\n",
        "        <p>{p6}</p>\n",
        "      </div>\n",
        "    </body>\n",
        "  </text>\n",
        "</TEI>\n",
        "\"\"\"\n",
        "\n",
        "# Write TEI XML document to file\n",
        "with open(\"output_142856_2-2.tei.xml\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(tei_xml)"
      ]
    }
  ]
}